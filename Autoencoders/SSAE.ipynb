{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stacked sparse autoencoder\n",
    "\n",
    "class StackedSparseAutoEncoder:\n",
    "    # imageshape: shape of patch, in x,y,z\n",
    "    # nFeatures: # of features for each level of encoder, number of decoders are the same\n",
    "    # sparsity: sparsity parameter for different number of stacks. This is useful when the encoder is built in \n",
    "    #    a stacked way. If built in a finetune way, only the last in the list is used.\n",
    "    # weight_decay: weight decay\n",
    "    # mode: 1 for L1 sparse, then the sparsity parameter means the penalty weights; \n",
    "    #       0 for K sparse, then the sparsity parameter means the number of non-zero elements for each level of encoder\n",
    "    def __init__(self, imgshape=[16,16,1], nFeatures=[1024,1024,1024], sparsity=[1,10,100], weight_decay=0.1, mode=1):\n",
    "        self.imgshape = imgshape\n",
    "        self.imgsize = imgshape[0] * imgshape[1]* imgshape[2]\n",
    "        self.nFeatures = nFeatures\n",
    "        self.sparsity = sparsity\n",
    "        self.weight_decay = weight_decay\n",
    "        self.mode = mode # 0 for K sparse, 1 for L1 sparse\n",
    "    \n",
    "    # build up encoder\n",
    "    def Encoder(self, input_data, scope='encoder', reuse=False, nFeatures=None):\n",
    "        with tf.variable_scope(scope, reuse = reuse):\n",
    "            if nFeatures is None:\n",
    "                nFeatures = self.nFeatures\n",
    "\n",
    "            encode_datas = list()\n",
    "            encode_datas.append(input_data)\n",
    "            h = tf.contrib.layers.flatten(input_data)            \n",
    "                        \n",
    "            for i in range(len(nFeatures)):\n",
    "                h = tf.layers.dense(h, nFeatures[i], tf.nn.relu, name='fc%d'%i)\n",
    "                encode_datas.append(h)\n",
    "        \n",
    "        with tf.variable_scope(scope, reuse = True):\n",
    "            encoder_weights = list()\n",
    "            encoder_biases = list()\n",
    "            for i in range(len(nFeatures)):\n",
    "                encoder_weights.append(tf.get_variable('fc%d/kernel'%i))\n",
    "                encoder_biases.append(tf.get_variable('fc%d/bias'%i))\n",
    "        \n",
    "        return encode_datas, encoder_weights, encoder_biases\n",
    "    \n",
    "    #build up decoder\n",
    "    def Decoder(self, encode_data, scope='decoder', reuse=False, nFeatures=None):\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            if nFeatures is None:\n",
    "                nFeatures = self.nFeatures[:-1]\n",
    "                        \n",
    "            decode_datas=list()\n",
    "            h = encode_data\n",
    "            decode_datas.append(h)\n",
    "                    \n",
    "            for i in range(len(nFeatures), 0, -1):\n",
    "                h = tf.layers.dense(h, nFeatures[i-1], tf.nn.relu, name='fc%d'%i)\n",
    "                decode_datas.append(h)\n",
    "            h = tf.layers.dense(h, self.imgsize, name='fc0')\n",
    "            decode_datas.append(tf.reshape(h, [tf.shape(h)[0]] + self.imgshape))\n",
    "        \n",
    "        with tf.variable_scope(scope, reuse = True):\n",
    "            decoder_weights = list()\n",
    "            decoder_biases = list()\n",
    "            for i in range(len(nFeatures), -1, -1):\n",
    "                decoder_weights.append(tf.get_variable('fc%d/kernel'%i)) \n",
    "                decoder_biases.append(tf.get_variable('fc%d/bias'%i)) \n",
    "        \n",
    "        return decode_datas, decoder_weights, decoder_biases\n",
    "    \n",
    "    # build the stacked autoencoder\n",
    "    # iStack: number of stacks to use (<= len(nFeatures)), this is useful when training layer by layer (which was \n",
    "    #    not used in the TMI paper)\n",
    "    def BuildStackedAutoEncoder(self, iStack=-1, scope='SSAE', reuse=False):\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            if iStack < 0 or iStack >= len(self.nFeatures):\n",
    "                iStack = len(self.nFeatures)-1\n",
    "            nFeatures = self.nFeatures[:(iStack+1)]\n",
    "            sparsity = self.sparsity[iStack]\n",
    "            \n",
    "            self.input_data = tf.placeholder(tf.float32, [None] + self.imgshape, name='input')\n",
    "            \n",
    "            self.encode_datas, encoder_weights, encoder_biases = \\\n",
    "                self.Encoder(self.input_data, scope='encoder', reuse=reuse, nFeatures=nFeatures)\n",
    "            \n",
    "            # explicitly apply K sparse constrains on the uppermost encoded layer\n",
    "            if self.mode == 0:\n",
    "                # k-sparse\n",
    "                self.encode_datas[-1] = self.KSparseMask(self.encode_datas[-1], sparsity)\n",
    "            \n",
    "            self.decode_datas, decoder_weights, decoder_biases = \\\n",
    "                self.Decoder(self.encode_datas[-1], scope='decoder', reuse=reuse, nFeatures=nFeatures[:-1])\n",
    "            \n",
    "            # build stack-wise losses, the features recovered by a decoder was compared to the  \n",
    "            #   features input to the corresponding encoder\n",
    "            self.losses = list()\n",
    "            for i in range(len(self.encode_datas)):\n",
    "                loss = tf.sqrt(tf.reduce_mean((self.encode_datas[i] - self.decode_datas[len(self.decode_datas)-i-1])**2))\n",
    "                self.losses.append(loss)\n",
    "            \n",
    "            self.loss_img = self.losses[0]  # image loss\n",
    "            self.loss_upmost = self.losses[-2]  # the upmost feature loss, useful for stacked training\n",
    "            self.loss_sparse = tf.reduce_mean(tf.abs(self.encode_datas[-1]))  # sparsity loss for L1 sparse\n",
    "            \n",
    "            # weight decay\n",
    "            self.loss_weight = 0\n",
    "            w_count = 0\n",
    "            for w in encoder_weights:\n",
    "                self.loss_weight += tf.reduce_mean(w**2)\n",
    "                w_count += 1\n",
    "            for w in decoder_weights:\n",
    "                self.loss_weight += tf.reduce_mean(w**2)\n",
    "                w_count += 1\n",
    "            self.loss_weight = tf.sqrt(self.loss_weight / w_count)\n",
    "            \n",
    "            # total loss\n",
    "            if self.mode == 0:\n",
    "                self.loss_current = self.loss_upmost + self.weight_decay * self.loss_weight\n",
    "                self.loss_total = self.loss_img + self.weight_decay * self.loss_weight\n",
    "            else:\n",
    "                self.loss_current = self.loss_upmost + sparsity * self.loss_sparse + self.weight_decay * self.loss_weight\n",
    "                self.loss_total = self.loss_img + sparsity * self.loss_sparse + self.weight_decay * self.loss_weight\n",
    "            \n",
    "            # vars\n",
    "            self.vars_encoder = encoder_weights + encoder_biases\n",
    "            self.vars_decoder = decoder_weights + decoder_biases\n",
    "            self.vars_upmost = [encoder_weights[-1], encoder_biases[-1], decoder_weights[0], decoder_biases[0]]\n",
    "    \n",
    "    # select the K largest element and set the rest to zero. it should be only computed during forward propagation\n",
    "    def KSparseMask(self, encode_data, sparsity, scope='SSAE', reuse=False):\n",
    "        with tf.variable_scope(scope, reuse):\n",
    "            h = encode_data\n",
    "            \n",
    "            _, indices = tf.nn.top_k(tf.abs(h), k=sparsity, name='top_k')\n",
    "            indices_dim1 = tf.expand_dims(tf.range(0, tf.shape(h)[0]), 1)\n",
    "            indices_dim1 = tf.tile(indices_dim1, [1, tf.shape(indices)[-1]])\n",
    "            full_indices = tf.concat([tf.expand_dims(indices_dim1, 2), tf.expand_dims(indices, 2)], 2)\n",
    "            full_indices = tf.reshape(full_indices, [-1, 2])\n",
    "            mask = tf.sparse_to_dense(full_indices, tf.shape(h), 1.0, validate_indices=False)\n",
    "            h = tf.multiply(h, mask)\n",
    "            \n",
    "            return h\n",
    "    \n",
    "    # given l = (y-f(x))^2, calculate dl / dx\n",
    "    def BuildGradientsWRTInput(self, scope='SSAE', reuse=False):\n",
    "        with tf.variable_scope(scope, reuse):\n",
    "            self.ref_data = tf.placeholder(tf.float32, [None] + self.imgshape, 'input_latent')\n",
    "            self.loss_ref = tf.sqrt(tf.reduce_mean((self.ref_data - self.decode_datas[-1])**2))\n",
    "            \n",
    "            self.grad_ref = tf.gradients(self.loss_ref, self.input_data)[0]\n",
    "            self.grad_sparse = tf.gradients(self.loss_sparse, self.input_data)[0]\n",
    "            self.grad_loss = tf.gradients(self.loss_img, self.input_data)[0]\n",
    "            \n",
    "            if self.mode == 0:\n",
    "                self.loss_ref_total = self.loss_ref\n",
    "                self.grad_ref_total = self.grad_ref\n",
    "            else:\n",
    "                self.loss_ref_total = self.loss_ref + self.sparsity[-1] * self.loss_sparse\n",
    "                self.grad_ref_total = self.grad_ref + self.sparsity[-1] * self.grad_sparse\n",
    "    \n",
    "    # predict f(x) for patches\n",
    "    def Predict(self, patches, batchsize, sess):\n",
    "        res_patches = np.zeros(patches.shape, np.float32)\n",
    "        for i in range(0, patches.shape[0], batchsize):\n",
    "            batch = patches[i:i+batchsize,...]\n",
    "            [res] = sess.run([self.decode_datas[-1]], feed_dict = {self.input_data: batch[...,np.newaxis]})\n",
    "            res_patches[i:i+batchsize,...] = res.squeeze()\n",
    "        \n",
    "        return res_patches\n",
    "    \n",
    "    # get the gradient (actual calculation)\n",
    "    def GetRefGradients(self, patches, ref_patches, batchsize, sess):\n",
    "        grads = np.zeros(patches.shape, np.float32)\n",
    "        for i in range(0, patches.shape[0], batchsize):\n",
    "            batch = patches[i:i+batchsize,...]\n",
    "            ref_batch = ref_patches[i:i+batchsize,...]\n",
    "            [grad] = sess.run([self.grad_ref_total], \n",
    "                              feed_dict = {self.input_data: batch[...,np.newaxis], \n",
    "                                           self.ref_data: ref_batch[...,np.newaxis]})\n",
    "            grads[i:i+batchsize,...] = grad.squeeze()\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    # get the loss (y-f(x))^2 (actual calculation)\n",
    "    def GetRefLoss(self, patches, refPatches, batchsize, sess):\n",
    "        vals = list()\n",
    "        for i in range(0, patches.shape[0], batchsize):\n",
    "            batch = patches[i:i+batchsize,...]\n",
    "            refBatch = refPatches[i:i+batchsize,...]\n",
    "            [val] = sess.run([self.loss_ref_total], \n",
    "                             feed_dict = {self.input_data: batch[...,np.newaxis], \n",
    "                                          self.ref_data: refBatch[...,np.newaxis]})\n",
    "            vals.append(val)\n",
    "        return sum(vals) / len(vals)\n",
    "    \n",
    "    # grey scale range transform, for patch grey scale range normalization\n",
    "    def MapGreyScaleRange(self, img, vmin, vmax, vmin_new, vmax_new, crop = True):\n",
    "        a = (vmax * vmin_new - vmin * vmax_new) / (vmax_new - vmin_new)\n",
    "        b = (vmax_new - vmin_new) / (vmax - vmin)\n",
    "        res = (img + a) * b\n",
    "        if crop is True:\n",
    "            res[res < vmin_new] = vmin_new\n",
    "            res[res > vmax_new] = vmax_new\n",
    "        \n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
