{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../FileOps/')\n",
    "import PatchSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# denoising (not used for the recon)\n",
    "def SAEDenoising(img, sae, sess, img_latent = None,\n",
    "                 strides = None, batchsize=1000, step=0.2, nSteps=10, calcLoss=False, random=True):\n",
    "    if strides is None:\n",
    "        strides = [sae.imgshape[0] / 2, sae.imgshape[1] / 2]\n",
    "    \n",
    "    if img_latent is None:\n",
    "        img_latent = np.copy(img)\n",
    "    \n",
    "    if random:\n",
    "        patches, x, y = PatchSample.MakePatches2DRandom(img, [sae.imgshape[0], sae.imgshape[1]], strides)\n",
    "    else:\n",
    "        patches, x, y = PatchSample.MakePatches2D(img, [sae.imgshape[0], sae.imgshape[1]], strides)\n",
    "    patches_latent,_,_ = PatchSample.MakePatches2DRandom(img_latent, [sae.imgshape[0], sae.imgshape[1]], strides, x, y)\n",
    "\n",
    "    for i in range(nSteps):\n",
    "        grads = sae.GetRefGradients(patches_latent, patches, batchsize, sess)\n",
    "        for j in range(grads.shape[0]):\n",
    "            grads[j,...] = grads[j,...] / np.linalg.norm(grads[j,...])\n",
    "        latent_patches = patches_latent - step * grads\n",
    "        if calcLoss:\n",
    "            loss = sae.GetRefLoss(patches_latent, patches, batchsize, sess)\n",
    "            print loss\n",
    "    \n",
    "    denoised_patches = sae.Predict(patches_latent, batchsize, sess)\n",
    "    \n",
    "    kernel = PatchSample.GetGaussianKernel([sae.imgshape[0], sae.imgshape[1]], sae.imgshape[0]/3.0)\n",
    "    denoised_img = PatchSample.AggregatePatches2D(denoised_patches, x, y, img.shape, kernel)\n",
    "    \n",
    "    return denoised_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQS step of the penalty\n",
    "# img: image to process\n",
    "# sae: the sparse autoencoder\n",
    "# sess: the session to run\n",
    "# img_latent: has to be None\n",
    "# patches_latent: should be None\n",
    "def SAEDenoisingSQS(img, sae, sess, img_latent=None, patches_latent = None,\n",
    "                    strides = None, batchsize=1000, step=0.05, nSteps=10, calcLoss=False, random=True):\n",
    "    if strides is None:\n",
    "        strides = [sae.imgshape[0] / 2, sae.imgshape[1] / 2]\n",
    "    if img_latent is None:\n",
    "        img_latent = np.copy(img)\n",
    "    \n",
    "    if random:\n",
    "        patches, x, y = PatchSample.MakePatches2DRandom(img, [sae.imgshape[0], sae.imgshape[1]], strides)\n",
    "    else:\n",
    "        patches, x, y = PatchSample.MakePatches2D(img, [sae.imgshape[0], sae.imgshape[1]], strides)\n",
    "    if patches_latent is None:\n",
    "        patches_latent,_, _ = PatchSample.MakePatches2DRandom(img_latent, [sae.imgshape[0], sae.imgshape[1]], \n",
    "                                                              strides, x, y)\n",
    "\n",
    "    for i in range(nSteps):\n",
    "        grads = sae.GetRefGradients(patches_latent, patches, batchsize, sess)\n",
    "        for j in range(grads.shape[0]):\n",
    "            grads[j,...] = grads[j,...] / np.linalg.norm(grads[j,...])\n",
    "        patches_latent = patches_latent - step * grads\n",
    "        if calcLoss:\n",
    "            loss = sae.GetRefLoss(patches_latent, patches, batchsize, sess)\n",
    "            print loss\n",
    "    denoised_patches = sae.Predict(patches_latent, batchsize, sess)\n",
    "    \n",
    "    kernel = np.ones([sae.imgshape[0], sae.imgshape[1]])\n",
    "    cf = np.sum((patches - denoised_patches)**2)\n",
    "    sum_difference = PatchSample.SumPatches2D(patches - denoised_patches, x, y, img.shape, kernel)\n",
    "    sum_ones = PatchSample.SumPatches2D(np.ones(patches.shape), x, y, img.shape, kernel)\n",
    "\n",
    "    return sum_difference, sum_ones, cf, patches_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAE SQS step for 3D\n",
    "def SAEDenoisingSQS3D(img, sae, sess, strides = None, batchsize=1000, step=0.1, nSteps=1, axis=0, output=True):\n",
    "    if strides is None:\n",
    "        strides = [sae.imgshape[0] / 2, sae.imgshape[1] / 2]\n",
    "    patchsize = [sae.imgshape[0], sae.imgshape[1]]\n",
    "    if axis != 0 and axis != 1 and axis != 2:\n",
    "        raise ValueError('axis must be one of 1, 2, 3')\n",
    "    \n",
    "    layer_zero = np.take(img, 0, axis)\n",
    "    x,y = PatchSample.GetPatchesCoordsRandom(layer_zero, patchsize, strides)\n",
    "    \n",
    "    patches = np.ones([len(x)*len(y), patchsize[0], patchsize[1]], np.float32)\n",
    "    \n",
    "    # get the normalize image\n",
    "    kernel = np.ones([sae.imgshape[0], sae.imgshape[1]])\n",
    "    sum_ones = PatchSample.SumPatches2D(np.ones(patches.shape), x, y, img.shape, kernel)\n",
    "    \n",
    "    sum_ones = np.repeat(np.expand_dims(sum_ones, axis), img.shape[axis], axis)\n",
    "    \n",
    "    sum_difference = np.zeros(img.shape, np.float32)\n",
    "    cf = 0\n",
    "    output_interval = img.shape[axis] / 20\n",
    "    for iLayer in range(img.shape[axis]):\n",
    "        if output and output_interval > 0:\n",
    "            if (iLayer + 1) % output_interval == 0:\n",
    "                print '%d...'%iLayer,\n",
    "        \n",
    "        imgLayer = np.copy(np.take(img, iLayer, axis))\n",
    "        # extract patches\n",
    "        FastPatch.ImgToPatchesWithCoords(patches, imgLayer, x, y)\n",
    "        patches_latent = np.copy(patches)\n",
    "        \n",
    "        # gradient descend\n",
    "        start = time.time()\n",
    "        for iStep in range(nSteps):\n",
    "            grads = sae.GetRefGradients(patches_latent, patches, batchsize, sess)\n",
    "            for j in range(grads.shape[0]):\n",
    "                grads[j,...] = grads[j,...] / np.linalg.norm(grads[j,...])\n",
    "            patches_latent = patches_latent - step * grads\n",
    "        denoised_patches = sae.Predict(patches_latent, batchsize, sess)\n",
    "        \n",
    "        # put the errors back\n",
    "        sumDiffLayer = np.zeros(imgLayer.shape, np.float32)\n",
    "        FastPatch.PatchesToImgWithCoordsSQS(sumDiffLayer, patches - denoised_patches, x, y)\n",
    "        if axis == 0:\n",
    "            sum_difference[iLayer, :, :] = sumDiffLayer\n",
    "        elif axis == 1:\n",
    "            sum_difference[:, iLayer, :] = sumDiffLayer\n",
    "        elif axis == 2:\n",
    "            sum_difference[:, :, iLayer] = sumDiffLayer\n",
    "        cf += np.sum((patches - denoised_patches)**2)\n",
    "    \n",
    "    return sum_difference, sum_ones, cf\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
